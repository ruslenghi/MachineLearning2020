## Predicting similarity of taste for foods given their photos (final grade 5/6)

### Challenge description:

In this task we are given a folder containing 10'000 pictures of different foods (not uploaded here for size constraints) and a training set consisting of ordered triplets (the dataset is divided into two equal parts of 5000 pictures: one is used for training and the other for the test). An ordered triplet might be [00002, 00034, 00018], meaning that the food in picture 00002.jpg is more similar in taste to the food in picture 00034.jpg then it is to the plate depicted in 00018.jpg. Given a triplet of the test set, our goal is to predict whether the first dish tastes more similar to the second (output 0) or third one (output 1).

### Solution:

For this task we followed a more intuitive and creative strategy. We loaded the weights pre-trained on 'imagenet' (not exclusively on food pictures) into tf.keras.applications. VGG16 neural network to the training set of images. When applied to an image, the pre-trained VGG16 returns a vector with about 350 entries corresponding to the set of possible categories (say pizza, or chair). Each entry stores the probability of the image to belong to that specific category. Furthermore, we performed **principal component analysis** (PCA) on these 350 dimensional vectors (this helped us reduce the runtime significantly). Then we exploited **unsupervised learning** through **k-means** to cluster the dimensionally reduced vectors. In order to make predictions, we built a grid with elements associated to pairs of classes, i.e. k-means clusters. In particular, consider we have again the training triplet [00002, 00034, 00018] and suppose that pictures are mapped to clusters ith, jth and kth ([00002, 00034, 00018] --> [i-th, j-th, k-th]). We then sum 1 to entries (i,j) and (j,i) in the grid, whereas we subtract 1 (i,k) and (k,i). 

For making predictions, we apply the same preprocessing (i.e. VGG16 regression and PCA) to test images, we then look at the clusters they belong to (previously computed thorugh k-means), and use the grids' values to measure taste similarity. Finally, we vary both the value of PCA components and the number of clusters of k-means and we use cross validation to test their goodness. As the performance varied just slightly while predictions were quite different (for different values of PCA components and K-means clusters) we made many predictions and picked the final one in a majority vote fashion. This method increased the score obtained through cross validation by nearly 10%, **with a final confidence of 65%**.
