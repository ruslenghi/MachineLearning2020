{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt \n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "import os, shutil, glob, os.path\n",
    "\n",
    "data_trainX = np.loadtxt('train_triplets.txt')\n",
    "data_testX = np.loadtxt('test_triplets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "time: 1h 36min 27s 10000\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model: imagenet\n",
    "image.LOAD_TRUNCATED_IMAGES = True \n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "imdir = 'food/'\n",
    "filelist = glob.glob(os.path.join(imdir, '*.jpg'))\n",
    "filelist.sort()\n",
    "\n",
    "featurelist = []\n",
    "for i, imagepath in enumerate(filelist):\n",
    "    try:\n",
    "        print(\"    Status: %s / %s\" %(i, len(filelist)), end=\"\\r\")\n",
    "        img = image.load_img(imagepath, target_size=(224, 224))\n",
    "        img_data = image.img_to_array(img)\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = preprocess_input(img_data)\n",
    "        features = np.array(model.predict(img_data))\n",
    "        featurelist.append(features.flatten())\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# optional: save model in pickle file\n",
    "# with open('featurelist_vgg16', 'wb') as fp:\n",
    "#    pickle.dump(featurelist, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.13 ms\n"
     ]
    }
   ],
   "source": [
    "def similarity_numbers (itemlist, triplets, triplets_test, ncat):\n",
    "    '''\n",
    "    This function computes a grid in which the elements are pairs of classes.\n",
    "    The elements of the grid are computed using triplets, which is an array \n",
    "    containing triplets. +1 is summed in the entry of the grid corresponding\n",
    "    to similar categories of each triplet element and -1 is summed when pairs\n",
    "    are less similar. The grid is used to make predictions on triples_test which\n",
    "    has the same structure as triplets.\n",
    "    '''\n",
    "    np.random.seed(4)\n",
    "    pairs = np.zeros((ncat, ncat))\n",
    "    \n",
    "    for i in range(len(triplets)):\n",
    "        first = itemlist[int(triplets[i][0])]\n",
    "        second = itemlist[int(triplets[i][1])]\n",
    "        third = itemlist[int(triplets[i][2])]\n",
    "        pairs[first,second] += 1\n",
    "        pairs[second,first] += 1\n",
    "        pairs[first,third] -= 1\n",
    "        pairs[third,first] -= 1\n",
    "    \n",
    "    predictions = []\n",
    "    for i in range(len(triplets_test)):\n",
    "        first_test = itemlist[int(triplets_test[i][0])]\n",
    "        second_test = itemlist[int(triplets_test[i][1])]\n",
    "        third_test = itemlist[int(triplets_test[i][2])]\n",
    "    \n",
    "        comparison_1 = pairs[first_test,second_test]\n",
    "        comparison_2 = pairs[first_test,third_test]\n",
    "        \n",
    "        if  comparison_1 > comparison_2:\n",
    "            predictions.append(1)\n",
    "        elif comparison_1 == comparison_2:\n",
    "            predictions.append(np.random.randint(2))\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "        \n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: load pickle file \n",
    "# with open ('featurelist_vgg16', 'rb') as fp:\n",
    "#    featurelist = pickle.load(fp)\n",
    "\n",
    "\"\"\"We figured that most of the predictions done by setting a fixed value for the PCA components \n",
    "and the number of clusters in the Kmeans performed comparably well in cv. However this predictions are quite\n",
    "different from one another. For this reason we exploited this diversity through the usage on an\n",
    "averaging technique. To have many predictions we ran two for loops, over PCA dimension and number of\n",
    "clusters in Kmeans. To ensure diversity of the predictions we measured distance between predictions \n",
    "and set the threshold = 20000, using cv. We then transformed the average values > 0.5 to 1 and < 0.5 to 0. \n",
    "This raised the cv score from 0.60 to 0.64.\n",
    "\"\"\"\n",
    "\n",
    "final = np.zeros(len(data_testX))\n",
    "\n",
    "threshold = 20000\n",
    "counter = 0\n",
    "M = []\n",
    "first = True\n",
    "for components in range(10,110,10):\n",
    "    print('PCA: ',components)\n",
    "    pca = PCA(n_components=components)\n",
    "    images_pca = pca.fit_transform(featurelist)\n",
    "    cluster_range = np.arange(10,110)\n",
    "    random.shuffle(cluster_range)\n",
    "    \n",
    "    for clusters in cluster_range:\n",
    "        print('cluster: ',clusters)\n",
    "        kmeans = KMeans(n_clusters=clusters, random_state=0).fit(np.array(images_pca))\n",
    "        pred = similarity_numbers(kmeans.labels_, data_trainX, data_testX, clusters)\n",
    "        if first: \n",
    "            M.append(pred)\n",
    "            counter += 1\n",
    "        first = False\n",
    "        check = True\n",
    "        for i in range(len(M)):\n",
    "            a = (np.linalg.norm(M[i]-pred))**2\n",
    "            if a < threshold: \n",
    "                check = False\n",
    "                \n",
    "        if check: \n",
    "            M.append(pred)\n",
    "            counter += 1\n",
    "\n",
    "M = np.array(M)\n",
    "for i in range(len(M)):\n",
    "    final += M[i]/len(M)\n",
    "\n",
    "predictions = np.zeros(len(final))\n",
    "for i in range(len(final)):\n",
    "    if final[i] > 0.5: predictions[i] = 1\n",
    "        \n",
    "np.savetxt(\"predictions.txt\", predictions, fmt=\"%i\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
